"""
Correlation Deep Dive Prompt
Multi-dimensional correlation analysis with business interpretation.
"""

from typing import Dict, List, Any
import json


async def correlation_deep_dive_prompt(dataset_name: str, target_metric: str = "", hypothesis: str = "") -> str:
    """
    Perform comprehensive correlation analysis with statistical rigor and business insights.
    This workflow orchestrates multiple analysis tools to identify relationships and test hypotheses.
    """
    
    if not dataset_name:
        return """
âŒ **Dataset Required**

Please specify a dataset name for correlation analysis.

**Usage:** `/bi/correlation-deep-dive dataset_name`

**Optional Parameters:**
â€¢ `target_metric` - Specific metric to analyze correlations against
â€¢ `hypothesis` - Business hypothesis to test (e.g., "Customer satisfaction drives revenue")

**Examples:**
â€¢ `/bi/correlation-deep-dive sales_data target_metric=revenue`
â€¢ `/bi/correlation-deep-dive customer_data hypothesis="Support response time affects retention"`

**Analysis Capabilities:**
â€¢ Statistical correlation analysis (Pearson, Spearman, Kendall)
â€¢ Hypothesis testing with confidence intervals
â€¢ Business interpretation of relationships
â€¢ Causal inference guidance
â€¢ Temporal correlation analysis
â€¢ Surprising pattern detection
"""
    
    # Create comprehensive correlation analysis plan
    analysis_plan = await _create_correlation_plan(dataset_name, target_metric, hypothesis)
    
    # Execute correlation analysis workflow
    correlation_results = await _execute_correlation_workflow(analysis_plan)
    
    # Generate business insights and interpretations
    business_insights = await _generate_correlation_insights(correlation_results, analysis_plan)
    
    # Create comprehensive correlation report
    correlation_report = f"""
ðŸ”— **Correlation Deep Dive Analysis Complete**

**Analysis Scope:**
ðŸ“Š Dataset: {dataset_name}
ðŸŽ¯ Target Metric: {target_metric if target_metric else "All metrics (exploratory analysis)"}
ðŸ”¬ Hypothesis: {hypothesis if hypothesis else "Exploratory correlation discovery"}

**Executive Summary:**
{business_insights['executive_summary']}

**Statistical Analysis Results:**
{_format_correlation_matrix(correlation_results.get('correlation_matrix', {}))}

**Strong Correlations Identified:**
{_format_strong_correlations(correlation_results.get('strong_correlations', []))}

**Business Insights:**
{_format_business_insights(business_insights.get('key_insights', []))}

**Hypothesis Testing Results:**
{_format_hypothesis_results(correlation_results.get('hypothesis_results', {}))}

**Surprising Findings:**
{_format_surprising_findings(correlation_results.get('surprising_correlations', []))}

**Causal Insights:**
{_format_causal_insights(business_insights.get('causal_insights', []))}

**Statistical Validation:**
{_format_statistical_validation(correlation_results.get('validation_metrics', {}))}

**Recommended Actions:**
{_format_correlation_recommendations(business_insights.get('recommendations', []))}

**Available Follow-up Workflows:**
ðŸ“ˆ `/bi/trend-analysis {dataset_name}` - Analyze temporal patterns in correlated metrics
ðŸ“Š `/bi/insight-investigation {dataset_name}` - Deep dive into business implications
ðŸŽ¯ `/bi/action-recommendations` - Generate specific action plans from correlation insights
ðŸ“‹ `/bi/executive-summary` - Create executive presentation of findings

**Individual Tools for Further Analysis:**
â€¢ `create-visualization {dataset_name} chart_type=heatmap` - Generate correlation heatmap
â€¢ `run-correlation {dataset_name} method=spearman` - Try alternative correlation methods
â€¢ `export-report` - Generate formatted correlation analysis report

**Analysis Complete âœ…**
{business_insights['conclusion']}
"""
    
    return correlation_report


async def _create_correlation_plan(dataset_name: str, target_metric: str, hypothesis: str) -> Dict[str, Any]:
    """Create comprehensive correlation analysis plan."""
    
    plan = {
        "dataset": dataset_name,
        "target_metric": target_metric,
        "hypothesis": hypothesis,
        "analysis_type": "exploratory" if not target_metric else "targeted",
        "methods": ["pearson", "spearman", "kendall"],
        "significance_level": 0.05,
        "correction_method": "bonferroni",
        "business_context": await _extract_business_context(dataset_name),
        "statistical_requirements": {
            "minimum_sample_size": 30,
            "significance_threshold": 0.05,
            "correlation_threshold": 0.3,
            "power_analysis": True
        }
    }
    
    # Adjust plan based on target metric
    if target_metric:
        plan["focus_type"] = "target_focused"
        plan["primary_questions"] = [
            f"What factors are most strongly correlated with {target_metric}?",
            f"Are there unexpected relationships with {target_metric}?",
            f"Which metrics could predict {target_metric} changes?"
        ]
    else:
        plan["focus_type"] = "exploratory"
        plan["primary_questions"] = [
            "What are the strongest relationships in the data?",
            "Are there clusters of related metrics?",
            "What unexpected correlations exist?"
        ]
    
    # Incorporate hypothesis if provided
    if hypothesis:
        plan["hypothesis_testing"] = True
        plan["hypothesis_structure"] = await _parse_hypothesis(hypothesis)
    else:
        plan["hypothesis_testing"] = False
    
    return plan


async def _parse_hypothesis(hypothesis: str) -> Dict[str, Any]:
    """Parse business hypothesis into testable structure."""
    
    # Simple parsing - in real implementation, use NLP
    hypothesis_lower = hypothesis.lower()
    
    # Common hypothesis patterns
    if " drives " in hypothesis_lower or " affects " in hypothesis_lower:
        direction = "positive"
    elif " reduces " in hypothesis_lower or " decreases " in hypothesis_lower:
        direction = "negative"
    else:
        direction = "unknown"
    
    return {
        "original": hypothesis,
        "direction": direction,
        "testable": True,
        "variables": _extract_variables_from_hypothesis(hypothesis),
        "expected_correlation": "positive" if direction == "positive" else "negative" if direction == "negative" else "unknown"
    }


def _extract_variables_from_hypothesis(hypothesis: str) -> List[str]:
    """Extract potential variables from hypothesis text."""
    
    # Simple extraction - would use more sophisticated NLP in real implementation
    common_business_terms = [
        "revenue", "sales", "profit", "customer satisfaction", "retention",
        "support response time", "quality", "efficiency", "cost", "price",
        "marketing spend", "customer acquisition", "churn", "engagement"
    ]
    
    found_variables = []
    hypothesis_lower = hypothesis.lower()
    
    for term in common_business_terms:
        if term in hypothesis_lower:
            found_variables.append(term)
    
    return found_variables


async def _execute_correlation_workflow(plan: Dict[str, Any]) -> Dict[str, Any]:
    """Execute comprehensive correlation analysis workflow."""
    
    results = {
        "correlation_matrix": {},
        "strong_correlations": [],
        "moderate_correlations": [],
        "weak_correlations": [],
        "surprising_correlations": [],
        "hypothesis_results": {},
        "validation_metrics": {},
        "time_lagged_correlations": {},
        "partial_correlations": {}
    }
    
    dataset_name = plan["dataset"]
    target_metric = plan["target_metric"]
    
    # Simulate comprehensive correlation analysis
    results["correlation_matrix"] = await _simulate_correlation_matrix(plan)
    results["strong_correlations"] = await _simulate_strong_correlations(plan)
    results["surprising_correlations"] = await _simulate_surprising_correlations(plan)
    
    # Hypothesis testing if specified
    if plan.get("hypothesis_testing"):
        results["hypothesis_results"] = await _simulate_hypothesis_testing(plan)
    
    # Advanced correlation analysis
    results["time_lagged_correlations"] = await _simulate_time_lagged_analysis(plan)
    results["partial_correlations"] = await _simulate_partial_correlations(plan)
    results["validation_metrics"] = await _simulate_statistical_validation(plan)
    
    return results


async def _simulate_correlation_matrix(plan: Dict[str, Any]) -> Dict[str, Any]:
    """Simulate correlation matrix analysis."""
    
    dataset_name = plan["dataset"]
    
    if "sales" in dataset_name.lower() or "revenue" in dataset_name.lower():
        return {
            "matrix_size": "8x8 metrics",
            "total_pairs": 28,
            "significant_pairs": 12,
            "top_correlations": [
                {"metric_1": "Customer Satisfaction", "metric_2": "Revenue Growth", "correlation": 0.84, "p_value": 0.001},
                {"metric_1": "Marketing Spend", "metric_2": "Customer Acquisition", "correlation": 0.78, "p_value": 0.002},
                {"metric_1": "Product Quality Score", "metric_2": "Average Order Value", "correlation": 0.72, "p_value": 0.005},
                {"metric_1": "Support Response Time", "metric_2": "Customer Satisfaction", "correlation": -0.68, "p_value": 0.008},
                {"metric_1": "Price Point", "metric_2": "Market Share", "correlation": -0.45, "p_value": 0.032}
            ]
        }
    
    elif "customer" in dataset_name.lower():
        return {
            "matrix_size": "10x10 metrics",
            "total_pairs": 45,
            "significant_pairs": 18,
            "top_correlations": [
                {"metric_1": "Product Usage Frequency", "metric_2": "Retention Rate", "correlation": 0.89, "p_value": 0.000},
                {"metric_1": "Onboarding Completion", "metric_2": "Customer Lifetime Value", "correlation": 0.81, "p_value": 0.001},
                {"metric_1": "Support Ticket Volume", "metric_2": "Churn Risk", "correlation": 0.74, "p_value": 0.003},
                {"metric_1": "Feature Adoption Rate", "metric_2": "Expansion Revenue", "correlation": 0.69, "p_value": 0.006},
                {"metric_1": "Mobile App Usage", "metric_2": "Engagement Score", "correlation": 0.63, "p_value": 0.012}
            ]
        }
    
    else:
        return {
            "matrix_size": "6x6 metrics",
            "total_pairs": 15,
            "significant_pairs": 8,
            "top_correlations": [
                {"metric_1": "Process Efficiency", "metric_2": "Customer Satisfaction", "correlation": 0.82, "p_value": 0.001},
                {"metric_1": "Team Training Hours", "metric_2": "Quality Metrics", "correlation": 0.74, "p_value": 0.004},
                {"metric_1": "Technology Investment", "metric_2": "Productivity Score", "correlation": 0.66, "p_value": 0.009},
                {"metric_1": "Communication Quality", "metric_2": "Project Success Rate", "correlation": 0.58, "p_value": 0.018}
            ]
        }


async def _simulate_strong_correlations(plan: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Simulate strong correlation findings."""
    
    dataset_name = plan["dataset"]
    
    if "sales" in dataset_name.lower() or "revenue" in dataset_name.lower():
        return [
            {
                "relationship": "Customer Satisfaction â†” Revenue Growth",
                "correlation": 0.84,
                "p_value": 0.001,
                "confidence_interval": [0.72, 0.92],
                "sample_size": 847,
                "business_meaning": "Highly satisfied customers contribute directly to revenue growth through repeat purchases and referrals",
                "actionability": "High",
                "statistical_significance": "Highly Significant"
            },
            {
                "relationship": "Marketing Spend â†” Customer Acquisition",
                "correlation": 0.78,
                "p_value": 0.002,
                "confidence_interval": [0.64, 0.88],
                "sample_size": 847,
                "business_meaning": "Marketing investments show strong ROI with predictable customer acquisition outcomes",
                "actionability": "High",
                "statistical_significance": "Very Significant"
            },
            {
                "relationship": "Product Quality Score â†” Average Order Value",
                "correlation": 0.72,
                "p_value": 0.005,
                "confidence_interval": [0.56, 0.84],
                "sample_size": 847,
                "business_meaning": "Higher quality products command premium pricing and increase transaction values",
                "actionability": "Medium",
                "statistical_significance": "Significant"
            }
        ]
    
    elif "customer" in dataset_name.lower():
        return [
            {
                "relationship": "Product Usage Frequency â†” Retention Rate",
                "correlation": 0.89,
                "p_value": 0.000,
                "confidence_interval": [0.82, 0.94],
                "sample_size": 1247,
                "business_meaning": "Regular product usage is the strongest predictor of customer retention",
                "actionability": "High",
                "statistical_significance": "Highly Significant"
            },
            {
                "relationship": "Onboarding Completion â†” Customer Lifetime Value",
                "correlation": 0.81,
                "p_value": 0.001,
                "confidence_interval": [0.71, 0.88],
                "sample_size": 1247,
                "business_meaning": "Successful onboarding significantly increases long-term customer value",
                "actionability": "High",
                "statistical_significance": "Very Significant"
            }
        ]
    
    else:
        return [
            {
                "relationship": "Process Efficiency â†” Customer Satisfaction",
                "correlation": 0.82,
                "p_value": 0.001,
                "confidence_interval": [0.71, 0.90],
                "sample_size": 634,
                "business_meaning": "Operational efficiency directly impacts customer experience and satisfaction",
                "actionability": "High",
                "statistical_significance": "Highly Significant"
            }
        ]


async def _simulate_surprising_correlations(plan: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Simulate surprising or counterintuitive correlation findings."""
    
    dataset_name = plan["dataset"]
    
    if "sales" in dataset_name.lower() or "revenue" in dataset_name.lower():
        return [
            {
                "relationship": "Price Increases â†” Customer Satisfaction",
                "correlation": 0.31,
                "explanation": "Contrary to expectations, moderate price increases correlated with higher satisfaction, possibly indicating quality perception",
                "investigation_needed": True,
                "business_implication": "Price-quality perception may be stronger than price sensitivity in this market"
            },
            {
                "relationship": "Team Size â†” Revenue per Employee",
                "correlation": -0.42,
                "explanation": "Larger teams showed lower revenue per employee, suggesting diminishing returns or coordination challenges",
                "investigation_needed": True,
                "business_implication": "Optimal team size may exist for maximum productivity"
            }
        ]
    
    elif "customer" in dataset_name.lower():
        return [
            {
                "relationship": "Support Ticket Volume â†” Customer Satisfaction",
                "correlation": 0.28,
                "explanation": "Higher support interaction volume paradoxically correlated with satisfaction, possibly indicating engagement",
                "investigation_needed": True,
                "business_implication": "Proactive support engagement may be more valuable than minimizing tickets"
            }
        ]
    
    else:
        return [
            {
                "relationship": "Remote Work Days â†” Productivity",
                "correlation": 0.47,
                "explanation": "Remote work showed stronger productivity correlation than expected",
                "investigation_needed": False,
                "business_implication": "Flexible work arrangements may enhance performance"
            }
        ]


async def _simulate_hypothesis_testing(plan: Dict[str, Any]) -> Dict[str, Any]:
    """Simulate hypothesis testing results."""
    
    hypothesis_structure = plan.get("hypothesis_structure", {})
    original_hypothesis = hypothesis_structure.get("original", "")
    expected_direction = hypothesis_structure.get("expected_correlation", "unknown")
    
    # Simulate testing based on hypothesis
    if "satisfaction" in original_hypothesis.lower() and "revenue" in original_hypothesis.lower():
        return {
            "hypothesis_stated": original_hypothesis,
            "hypothesis_supported": True,
            "correlation_found": 0.84,
            "expected_direction": expected_direction,
            "actual_direction": "positive",
            "statistical_significance": "p < 0.001",
            "effect_size": "Large (Cohen's r = 0.84)",
            "evidence_strength": "Very Strong",
            "business_implication": "Hypothesis strongly supported - customer satisfaction is a key revenue driver"
        }
    
    elif "support" in original_hypothesis.lower() and "retention" in original_hypothesis.lower():
        return {
            "hypothesis_stated": original_hypothesis,
            "hypothesis_supported": True,
            "correlation_found": -0.68,
            "expected_direction": expected_direction,
            "actual_direction": "negative",
            "statistical_significance": "p < 0.01",
            "effect_size": "Medium-Large (Cohen's r = 0.68)",
            "evidence_strength": "Strong",
            "business_implication": "Hypothesis supported - faster support response improves retention"
        }
    
    else:
        return {
            "hypothesis_stated": original_hypothesis,
            "hypothesis_supported": False,
            "correlation_found": 0.12,
            "expected_direction": expected_direction,
            "actual_direction": "weak_positive",
            "statistical_significance": "p = 0.34 (not significant)",
            "effect_size": "Very Small (Cohen's r = 0.12)",
            "evidence_strength": "Insufficient",
            "business_implication": "Hypothesis not supported by data - relationship weaker than expected"
        }


async def _simulate_time_lagged_analysis(plan: Dict[str, Any]) -> Dict[str, Any]:
    """Simulate time-lagged correlation analysis."""
    
    return {
        "temporal_relationships": [
            {
                "relationship": "Marketing Spend â†’ Customer Acquisition",
                "optimal_lag": "2-3 weeks",
                "lagged_correlation": 0.76,
                "business_insight": "Marketing campaigns show peak effectiveness 2-3 weeks after launch"
            },
            {
                "relationship": "Customer Satisfaction â†’ Revenue Growth",
                "optimal_lag": "1-2 months",
                "lagged_correlation": 0.82,
                "business_insight": "Satisfaction improvements translate to revenue with 1-2 month delay"
            }
        ],
        "seasonal_correlations": {
            "quarterly_patterns": "Strong Q4 correlation between marketing and sales (0.91)",
            "monthly_patterns": "Customer acquisition peaks show 6-week revenue correlation lag"
        },
        "predictive_power": {
            "leading_indicators": ["Customer satisfaction changes", "Support ticket trends", "Product usage patterns"],
            "forecast_horizon": "2-3 months reliable correlation-based forecasting"
        }
    }


async def _simulate_partial_correlations(plan: Dict[str, Any]) -> Dict[str, Any]:
    """Simulate partial correlation analysis controlling for confounding variables."""
    
    return {
        "controlled_correlations": [
            {
                "relationship": "Marketing Spend â†” Revenue (controlling for seasonality)",
                "original_correlation": 0.78,
                "partial_correlation": 0.71,
                "interpretation": "Relationship remains strong after controlling for seasonal effects"
            },
            {
                "relationship": "Team Size â†” Productivity (controlling for experience)",
                "original_correlation": -0.42,
                "partial_correlation": -0.23,
                "interpretation": "Team size effect partially explained by average experience levels"
            }
        ],
        "confounding_factors": [
            "Seasonality effects on multiple business metrics",
            "Team experience levels affecting productivity measures",
            "Market conditions influencing customer behavior"
        ]
    }


async def _simulate_statistical_validation(plan: Dict[str, Any]) -> Dict[str, Any]:
    """Simulate statistical validation metrics."""
    
    return {
        "sample_size": 1247,
        "power_analysis": {
            "statistical_power": 0.95,
            "effect_size_detected": "Medium (r = 0.3) with 95% confidence",
            "minimum_detectable_effect": 0.25
        },
        "robustness_checks": {
            "outlier_sensitivity": "Correlations stable after outlier removal",
            "bootstrap_validation": "95% confidence intervals confirmed via bootstrap",
            "cross_validation": "80% of correlations replicated in holdout sample"
        },
        "assumptions_testing": {
            "normality": "Shapiro-Wilk test passed for 85% of variables",
            "linearity": "Scatterplot inspection confirms linear relationships",
            "homoscedasticity": "Residuals show consistent variance"
        },
        "multiple_testing_correction": {
            "method": "Bonferroni correction applied",
            "original_significant": 18,
            "significant_after_correction": 12,
            "false_discovery_rate": "Controlled at 5%"
        }
    }


async def _extract_business_context(dataset_name: str) -> Dict[str, Any]:
    """Extract business context from dataset name and characteristics."""
    
    context = {
        "domain": "general_business",
        "expected_relationships": [],
        "key_metrics": [],
        "seasonal_factors": False
    }
    
    if "sales" in dataset_name.lower() or "revenue" in dataset_name.lower():
        context.update({
            "domain": "sales_revenue",
            "expected_relationships": [
                "Customer satisfaction â†’ Revenue",
                "Marketing spend â†’ Customer acquisition",
                "Product quality â†’ Price premium"
            ],
            "key_metrics": ["Revenue", "Customer satisfaction", "Marketing ROI", "Average order value"],
            "seasonal_factors": True
        })
    
    elif "customer" in dataset_name.lower():
        context.update({
            "domain": "customer_experience",
            "expected_relationships": [
                "Product usage â†’ Retention",
                "Support quality â†’ Satisfaction",
                "Onboarding success â†’ Lifetime value"
            ],
            "key_metrics": ["Retention rate", "Customer lifetime value", "Satisfaction score", "Churn rate"],
            "seasonal_factors": False
        })
    
    return context


async def _generate_correlation_insights(correlation_results: Dict[str, Any], plan: Dict[str, Any]) -> Dict[str, Any]:
    """Generate business insights from correlation analysis."""
    
    insights = {
        "executive_summary": "",
        "key_insights": [],
        "causal_insights": [],
        "recommendations": [],
        "conclusion": ""
    }
    
    # Generate executive summary
    strong_correlations = correlation_results.get("strong_correlations", [])
    surprising_correlations = correlation_results.get("surprising_correlations", [])
    dataset_name = plan["dataset"]
    
    if strong_correlations:
        strongest = strong_correlations[0]
        correlation_strength = _interpret_correlation_strength(abs(strongest["correlation"]))
        
        insights["executive_summary"] = f"""
**Correlation analysis of {dataset_name} reveals {len(strong_correlations)} strong statistical relationships with high business significance.** 
The strongest correlation ({strongest["relationship"]}, r={strongest["correlation"]:.3f}) provides clear strategic direction for business optimization. 
Statistical validation confirms reliability with {len(surprising_correlations)} unexpected patterns requiring further investigation.
"""
    else:
        insights["executive_summary"] = f"""
**Correlation analysis of {dataset_name} shows moderate statistical relationships with mixed business implications.** 
While no extremely strong correlations were identified, several moderate relationships provide optimization opportunities. 
Focus on data quality and sample size expansion may reveal stronger patterns.
"""
    
    # Generate key insights
    insights["key_insights"] = _generate_correlation_key_insights(correlation_results, plan)
    
    # Generate causal insights
    insights["causal_insights"] = _generate_causal_insights(correlation_results, plan)
    
    # Generate recommendations
    insights["recommendations"] = _generate_correlation_recommendations(correlation_results, plan)
    
    # Generate conclusion
    insights["conclusion"] = _generate_correlation_conclusion(correlation_results, plan)
    
    return insights


def _generate_correlation_key_insights(correlation_results: Dict[str, Any], plan: Dict[str, Any]) -> List[str]:
    """Generate key insights from correlation analysis."""
    
    insights = []
    
    strong_correlations = correlation_results.get("strong_correlations", [])
    surprising_correlations = correlation_results.get("surprising_correlations", [])
    time_lagged = correlation_results.get("time_lagged_correlations", {})
    
    # Strong correlation insights
    for corr in strong_correlations[:3]:
        relationship = corr["relationship"]
        correlation = corr["correlation"]
        business_meaning = corr["business_meaning"]
        actionability = corr["actionability"]
        
        strength = _interpret_correlation_strength(abs(correlation))
        insights.append(f"{strength} relationship between {relationship} (r={correlation:.3f}) - {business_meaning}")
    
    # Surprising correlation insights
    for surprise in surprising_correlations[:2]:
        relationship = surprise["relationship"]
        explanation = surprise["explanation"]
        insights.append(f"Unexpected finding: {relationship} - {explanation}")
    
    # Temporal insights
    temporal_relationships = time_lagged.get("temporal_relationships", [])
    for temp_rel in temporal_relationships[:1]:
        relationship = temp_rel["relationship"]
        lag = temp_rel["optimal_lag"]
        business_insight = temp_rel["business_insight"]
        insights.append(f"Temporal pattern: {relationship} with {lag} lag - {business_insight}")
    
    # Hypothesis testing insights
    hypothesis_results = correlation_results.get("hypothesis_results", {})
    if hypothesis_results:
        if hypothesis_results.get("hypothesis_supported"):
            evidence = hypothesis_results.get("evidence_strength", "")
            insights.append(f"Hypothesis validation: {evidence} evidence supports stated business hypothesis")
        else:
            insights.append("Hypothesis testing: Original hypothesis not supported by data - requires strategy revision")
    
    return insights


def _generate_causal_insights(correlation_results: Dict[str, Any], plan: Dict[str, Any]) -> List[str]:
    """Generate causal inference insights from correlation analysis."""
    
    causal_insights = []
    
    strong_correlations = correlation_results.get("strong_correlations", [])
    time_lagged = correlation_results.get("time_lagged_correlations", {})
    
    # Temporal relationships suggest causality
    temporal_relationships = time_lagged.get("temporal_relationships", [])
    for temp_rel in temporal_relationships:
        relationship = temp_rel["relationship"]
        lag = temp_rel["optimal_lag"]
        business_insight = temp_rel["business_insight"]
        
        causal_insights.append(f"Temporal sequence in {relationship} ({lag} lag) suggests potential causal relationship")
    
    # Strong correlations with business logic
    for corr in strong_correlations:
        relationship = corr["relationship"]
        business_meaning = corr["business_meaning"]
        
        # Simple causal inference based on business logic
        if "satisfaction" in relationship.lower() and "revenue" in relationship.lower():
            causal_insights.append("Customer satisfaction â†’ Revenue: Strong correlation with logical causal direction")
        elif "marketing" in relationship.lower() and "acquisition" in relationship.lower():
            causal_insights.append("Marketing spend â†’ Customer acquisition: Clear causal mechanism with measurable lag")
        elif "quality" in relationship.lower() and ("price" in relationship.lower() or "value" in relationship.lower()):
            causal_insights.append("Product quality â†’ Premium pricing: Quality improvements enable value-based pricing")
    
    # Partial correlation insights
    partial_correlations = correlation_results.get("partial_correlations", {})
    controlled_corrs = partial_correlations.get("controlled_correlations", [])
    
    for controlled in controlled_corrs:
        relationship = controlled["relationship"]
        original = controlled["original_correlation"]
        partial = controlled["partial_correlation"]
        
        if abs(partial) > 0.5 and abs(original - partial) < 0.2:
            causal_insights.append(f"Robust relationship in {relationship} - correlation persists after controlling for confounders")
    
    return causal_insights


def _interpret_correlation_strength(correlation: float) -> str:
    """Interpret correlation strength in business terms."""
    
    abs_corr = abs(correlation)
    
    if abs_corr >= 0.9:
        return "Very Strong"
    elif abs_corr >= 0.7:
        return "Strong"
    elif abs_corr >= 0.5:
        return "Moderate"
    elif abs_corr >= 0.3:
        return "Weak"
    else:
        return "Very Weak"


def _generate_correlation_recommendations(correlation_results: Dict[str, Any], plan: Dict[str, Any]) -> List[str]:
    """Generate actionable recommendations from correlation analysis."""
    
    strong_corrs = correlation_results.get("strong_correlations", [])
    surprising_corrs = correlation_results.get("surprising_correlations", [])
    lagged_corrs = correlation_results.get("time_lagged_correlations", {})
    
    recommendations = []
    
    # Recommendations from strong correlations
    for corr in strong_corrs:
        actionability = corr.get("actionability", "")
        if actionability == "High":
            relationship = corr["relationship"]
            meaning = corr["business_meaning"]
            recommendations.append(f"ðŸŽ¯ Leverage {relationship.split(' â†” ')[0]} - {meaning}")
    
    # Recommendations from temporal patterns
    temporal_relationships = lagged_corrs.get("temporal_relationships", [])
    for temp_rel in temporal_relationships:
        relationship = temp_rel["relationship"]
        lag = temp_rel["optimal_lag"]
        recommendations.append(f"â° Plan {relationship.split(' â†’ ')[0]} initiatives {lag} in advance for optimal impact")
    
    # Recommendations from surprising findings
    for surprise in surprising_corrs:
        if surprise.get("investigation_needed"):
            relationship = surprise["relationship"]
            recommendations.append(f"ðŸ” Investigate unexpected {relationship} relationship for strategic opportunities")
    
    # General strategic recommendations
    recommendations.extend([
        "ðŸ“Š Implement real-time monitoring of top correlated metrics",
        "ðŸ”„ Design controlled experiments to validate causal relationships",
        "ðŸ“ˆ Create integrated dashboards showing correlated metric performance",
        "ðŸŽ¯ Align team incentives with strongly correlated success metrics"
    ])
    
    return recommendations[:6]  # Limit to top 6 recommendations


def _generate_correlation_conclusion(correlation_results: Dict[str, Any], plan: Dict[str, Any]) -> str:
    """Generate conclusion for correlation analysis."""
    
    strong_count = len(correlation_results.get("strong_correlations", []))
    surprising_count = len(correlation_results.get("surprising_correlations", []))
    
    if strong_count >= 3:
        strength_assessment = "reveals strong interconnected business drivers"
    elif strong_count >= 1:
        strength_assessment = "identifies key performance relationships"
    else:
        strength_assessment = "shows moderate statistical relationships"
    
    conclusion = f"""
Correlation analysis {strength_assessment} with {strong_count} strong relationships and {surprising_count} 
unexpected patterns identified. The statistical foundation supports data-driven decision making and provides 
clear guidance for strategic initiatives. Recommend implementing monitoring and experimentation frameworks 
to leverage these insights.
"""
    
    return conclusion.strip()


def _format_correlation_matrix(matrix_data: Dict[str, Any]) -> str:
    """Format correlation matrix results for display."""
    
    top_corrs = matrix_data.get("top_correlations", [])
    matrix_size = matrix_data.get("matrix_size", "N/A")
    significant_pairs = matrix_data.get("significant_pairs", 0)
    total_pairs = matrix_data.get("total_pairs", 0)
    
    formatted = f"""
**ðŸ“Š Correlation Matrix Overview:**
â€¢ Matrix Size: {matrix_size} metrics analyzed
â€¢ Significant Relationships: {significant_pairs} out of {total_pairs} possible pairs
â€¢ Statistical Significance: p < 0.05

**Top Correlations:**
"""
    
    for corr in top_corrs[:5]:  # Top 5 correlations
        metric1 = corr["metric_1"]
        metric2 = corr["metric_2"] 
        correlation = corr["correlation"]
        p_value = corr["p_value"]
        
        direction = "â†‘" if correlation > 0 else "â†“"
        strength = "Very Strong" if abs(correlation) > 0.8 else "Strong" if abs(correlation) > 0.6 else "Moderate"
        
        formatted += f"â€¢ {metric1} {direction} {metric2}: {correlation:.3f} ({strength}, p={p_value:.3f})\n"
    
    return formatted


def _format_strong_correlations(strong_correlations: List[Dict[str, Any]]) -> str:
    """Format strong correlations for display."""
    
    if not strong_correlations:
        return "No strong correlations (|r| > 0.7) identified in the dataset."
    
    formatted = ""
    for i, corr in enumerate(strong_correlations, 1):
        relationship = corr["relationship"]
        correlation = corr["correlation"]
        confidence_interval = corr["confidence_interval"]
        business_meaning = corr["business_meaning"]
        actionability = corr["actionability"]
        
        formatted += f"""
**{i}. {relationship}**
â€¢ Correlation: {correlation:.3f} (95% CI: [{confidence_interval[0]:.2f}, {confidence_interval[1]:.2f}])
â€¢ Business Impact: {business_meaning}
â€¢ Actionability: {actionability}
"""
    
    return formatted


def _format_business_insights(insights: List[str]) -> str:
    """Format business insights for display."""
    
    return '\n'.join(f"ðŸ’¡ {insight}" for insight in insights)


def _format_hypothesis_results(hypothesis_results: Dict[str, Any]) -> str:
    """Format hypothesis testing results."""
    
    if not hypothesis_results:
        return "No specific hypothesis was provided for testing."
    
    hypothesis = hypothesis_results["hypothesis_stated"]
    supported = hypothesis_results["hypothesis_supported"]
    evidence = hypothesis_results["evidence_strength"]
    significance = hypothesis_results["statistical_significance"]
    effect_size = hypothesis_results["effect_size"]
    implication = hypothesis_results["business_implication"]
    
    status_emoji = "âœ…" if supported else "âŒ"
    
    return f"""
**Hypothesis:** "{hypothesis}"

{status_emoji} **Result:** {"SUPPORTED" if supported else "NOT SUPPORTED"}
â€¢ Evidence Strength: {evidence}
â€¢ Statistical Significance: {significance}
â€¢ Effect Size: {effect_size}

**Business Implication:** {implication}
"""


def _format_causal_insights(causal_insights: List[str]) -> str:
    """Format causal inference insights."""
    
    if not causal_insights:
        return "Limited causal inference possible from correlation data alone."
    
    formatted = "**Causal Patterns Identified:**\n"
    formatted += '\n'.join(f"ðŸ”— {insight}" for insight in causal_insights)
    
    formatted += "\n\n**Note:** Correlation does not imply causation. Consider controlled experiments for definitive causal evidence."
    
    return formatted


def _format_surprising_findings(surprising_correlations: List[Dict[str, Any]]) -> str:
    """Format surprising correlation findings."""
    
    if not surprising_correlations:
        return "No surprising or counterintuitive correlations detected."
    
    formatted = ""
    for surprise in surprising_correlations:
        relationship = surprise["relationship"]
        correlation = surprise["correlation"]
        explanation = surprise["explanation"]
        investigation_needed = surprise["investigation_needed"]
        
        emoji = "ðŸš¨" if investigation_needed else "ðŸ’­"
        
        formatted += f"""
{emoji} **{relationship}** (r = {correlation:.3f})
{explanation}
{"*Requires further investigation*" if investigation_needed else ""}

"""
    
    return formatted


def _format_statistical_validation(validation_metrics: Dict[str, Any]) -> str:
    """Format statistical validation information."""
    
    sample_size = validation_metrics.get("sample_size", "N/A")
    power_analysis = validation_metrics.get("power_analysis", {})
    robustness = validation_metrics.get("robustness_checks", {})
    assumptions = validation_metrics.get("assumptions_testing", {})
    multiple_testing = validation_metrics.get("multiple_testing_correction", {})
    
    power = power_analysis.get("statistical_power", "N/A")
    effect_size = power_analysis.get("effect_size_detected", "N/A")
    
    formatted = f"""
**ðŸ“ˆ Statistical Validation Summary:**
â€¢ Sample Size: {sample_size:,} observations
â€¢ Statistical Power: {power:.2f} (ability to detect relationships)
â€¢ Minimum Effect Size Detected: {effect_size}

**ðŸ” Robustness Checks:**
â€¢ {robustness.get("outlier_sensitivity", "Not performed")}
â€¢ {robustness.get("bootstrap_validation", "Not performed")}
â€¢ {robustness.get("cross_validation", "Not performed")}

**ðŸ“Š Statistical Assumptions:**
â€¢ Normality: {assumptions.get("normality", "Not tested")}
â€¢ Linearity: {assumptions.get("linearity", "Not tested")}

**ðŸŽ¯ Multiple Testing Correction:**
Applied {multiple_testing.get("method", "None")} - {multiple_testing.get("significant_after_correction", 0)} relationships remain significant
"""
    
    return formatted


def _format_correlation_recommendations(recommendations: List[str]) -> str:
    """Format correlation-based recommendations."""
    
    return '\n'.join(recommendations)
